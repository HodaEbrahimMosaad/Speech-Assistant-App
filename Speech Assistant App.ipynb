{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "import webrtcvad\n",
    "import wave\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import pyaudio\n",
    "import wave\n",
    "import os, sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import webbrowser\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "from gtts import gTTS\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    global counter \n",
    "    counter+=1\n",
    "    vad = webrtcvad.Vad()\n",
    "    vad.set_mode(2)\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 32000\n",
    "    CHUNK = 960\n",
    "    RECORD_SECONDS = 4\n",
    "    WAVE_OUTPUT_FILENAME = \"order/file\"+str(counter)+\".wav\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    while True:\n",
    "\n",
    "        frames = []\n",
    "        frameCount = 0\n",
    "\n",
    "        while frameCount:\n",
    "            data = stream.read(CHUNK)\n",
    "\n",
    "            if vad.is_speech(data, RATE):\n",
    "                frameCount+=1;\n",
    "            else:\n",
    "                frameCount = 0;\n",
    "            # print frameCount\n",
    "\n",
    "        print (\"recording...\")\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "        print(\"finished recording\")\n",
    "\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "        # change this as you see fit\n",
    "        audio_path = \"order/file\"+str(counter)+\".wav\"\n",
    "\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        break;\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio as p\n",
    "print(p.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def record(ask = False):\n",
    "    if ask:\n",
    "        speak(ask)\n",
    "    path = record_audio()\n",
    "    print(path)\n",
    "    voice = sr.AudioFile(path)\n",
    "    with voice as source:\n",
    "        audio = r.record(source)\n",
    "        voice_data = ''\n",
    "        try:\n",
    "            voice_data = r.recognize_google(audio)  # convert audio to text\n",
    "        except sr.UnknownValueError: # error: recognizer does not understand\n",
    "            speak('I did not get that')\n",
    "        except sr.RequestError:\n",
    "            speak('Sorry, the service is down') # error: recognizer is not connected\n",
    "        print(f\"{voice_data.lower()}\") # print what user said\n",
    "        return voice_data.lower()\n",
    "    \n",
    "def responde(voice_data):\n",
    "    if \"your name\" in voice_data:\n",
    "        speak('my name is mooohsseeeennaaaa')\n",
    "    if \"bye\" in voice_data:\n",
    "        speak('see you')\n",
    "    if \"what time\" in voice_data:\n",
    "        speak(datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\"))\n",
    "    if \"search\" in voice_data:\n",
    "        search = record('What do you want to search for?')\n",
    "        url = \"https://google.com/search?q=\"+search\n",
    "        webbrowser.get().open(url)\n",
    "        speak('Here is what I found for ' + search + \" on google\")\n",
    "    if \"location\" in voice_data:\n",
    "        location = record('What is the location ?')\n",
    "        url = \"https://google.nl/maps/place/\"+location+\"/&amp;\"\n",
    "        webbrowser.get().open(url)\n",
    "        speak('Here is the location of ' + location + \" on google\")\n",
    "    if \"exit\" in voice_data:\n",
    "        exit()\n",
    "        \n",
    "def speak(audio_string):\n",
    "    tts = gTTS(text=audio_string, lang='en')\n",
    "    r = random.randint(1,20000000)\n",
    "    audio_file = 'audio' + str(r) + '.mp3'\n",
    "    tts.save(audio_file)\n",
    "    playsound(audio_file)\n",
    "    print(audio_string) \n",
    "    os.remove(audio_file) \n",
    "        \n",
    "time.sleep(1)    \n",
    "speak('How can I help you?')\n",
    "while 1:\n",
    "    voice_data = record()\n",
    "    responde(voice_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
